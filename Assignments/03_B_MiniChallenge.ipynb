{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductory applied machine learning (INFR10069)\n",
    "# Assignment 3 (Part B): Mini-Challenge [25%]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Instructions\n",
    "\n",
    "**It is important that you follow the instructions below to the letter - we will not be responsible for incorrect marking due to non-standard practices.**\n",
    "\n",
    "1. <font color='red'>We have split Assignment 3 into two parts to make it easier for you to work on them separately and for the markers to give you feedback. This is part B of Assignment 3 - Part A is an introduction to Object Recognition. Both Assignments together are still worth 50% of CourseWork 2. **Remember to submit both notebooks (you can submit them separately).**</font>\n",
    "\n",
    "1. You *MUST* have your environment set up as in the [README](https://github.com/michael-camilleri/IAML2018) and you *must activate this environment before running this notebook*:\n",
    "```\n",
    "source activate py3iaml\n",
    "cd [DIRECTORY CONTAINING GIT REPOSITORY]\n",
    "jupyter notebook\n",
    "# Navigate to this file\n",
    "```\n",
    "\n",
    "1. Read the instructions carefully, especially where asked to name variables with a specific name. Wherever you are required to produce code you should use code cells, otherwise you should use markdown cells to report results and explain answers. In most cases we indicate the nature of answer we are expecting (code/text), and also provide the code/markdown cell where to put it\n",
    "\n",
    "1. This part of the Assignment is the same for all students i.e. irrespective of whether you are taking the Level 10 version (INFR10069) or the Level-11 version of the course (INFR11182 and INFR11152).\n",
    "\n",
    "1. The .csv files that you will be using are located at `./datasets` (i.e. use the `datasets` directory **adjacent** to this file).\n",
    "\n",
    "1. In the textual answer, you are given a word-count limit of 600 words: exceeding this will lead to penalisation.\n",
    "\n",
    "1. Make sure to distinguish between **attributes** (columns of the data) and **features** (which typically refers only to the independent variables, i.e. excluding the target variables).\n",
    "\n",
    "1. Make sure to show **all** your code/working. \n",
    "\n",
    "1. Write readable code. While we do not expect you to follow [PEP8](https://www.python.org/dev/peps/pep-0008/) to the letter, the code should be adequately understandable, with plots/visualisations correctly labelled. **Do** use inline comments when doing something non-standard. When asked to present numerical values, make sure to represent real numbers in the appropriate precision to exemplify your answer. Marks *WILL* be deducted if the marker cannot understand your logic/results.\n",
    "\n",
    "1. **Collaboration:** You may discuss the assignment with your colleagues, provided that the writing that you submit is entirely your own. That is, you must NOT borrow actual text or code from others. We ask that you provide a list of the people who you've had discussions with (if any). Please refer to the [Academic Misconduct](http://web.inf.ed.ac.uk/infweb/admin/policies/academic-misconduct) page for what consistutes a breach of the above.\n",
    "\n",
    "\n",
    "### SUBMISSION Mechanics\n",
    "\n",
    "**IMPORTANT:** You must submit this assignment by **Thursday 15/11/2018 at 16:00**. \n",
    "\n",
    "**Late submissions:** The policy stated in the School of Informatics is that normally you will not be allowed to submit coursework late. See the [ITO webpage](http://web.inf.ed.ac.uk/infweb/student-services/ito/admin/coursework-projects/late-coursework-extension-requests) for exceptions to this, e.g. in case of serious medical illness or serious personal problems.\n",
    "\n",
    "**Resubmission:** If you submit your file(s) again, the previous submission is **overwritten**. We will mark the version that is in the submission folder at the deadline.\n",
    "\n",
    "**N.B.**: This Assignment requires submitting **two files (electronically as described below)**:\n",
    " 1. This Jupyter Notebook (Part B), *and*\n",
    " 1. The Jupyter Notebook for Part A\n",
    " \n",
    "All submissions happen electronically. To submit:\n",
    "\n",
    "1. Fill out this notebook (as well as Part A), making sure to:\n",
    "   1. save it with **all code/text and visualisations**: markers are NOT expected to run any cells,\n",
    "   1. keep the name of the file **UNCHANGED**, *and*\n",
    "   1. **keep the same structure**: retain the questions, **DO NOT** delete any cells and **avoid** adding unnecessary cells unless absolutely necessary, as this makes the job harder for the markers. This is especially important for the textual description and probability output (below).\n",
    "\n",
    "1. Submit it using the `submit` functionality. To do this, you must be on a DICE environment. Open a Terminal, and:\n",
    "   1. **On-Campus Students**: navigate to the location of this notebook and execute the following command:\n",
    "   \n",
    "      ```submit iaml cw2 03_A_ObjectRecognition.ipynb 03_B_MiniChallenge.ipynb```\n",
    "      \n",
    "   1. **Distance Learners:** These instructions also apply to those students who work on their own computer. First you need to copy your work onto DICE (so that you can use the `submit` command). For this, you can use `scp` or `rsync` (you may need to install these yourself). You can copy files to `student.ssh.inf.ed.ac.uk`, then ssh into it in order to submit. The following is an example. Replace entries in `[square brackets]` with your specific details: i.e. if your student number is for example s1234567, then `[YOUR USERNAME]` becomes `s1234567`.\n",
    "   \n",
    "    ```\n",
    "    scp -r [FULL PATH TO 03_A_ObjectRecognition.ipynb] [YOUR USERNAME]@student.ssh.inf.ed.ac.uk:03_A_ObjectRecognition.ipynb\n",
    "    scp -r [FULL PATH TO 03_B_MiniChallenge.ipynb] [YOUR USERNAME]@student.ssh.inf.ed.ac.uk:03_B_MiniChallenge.ipynb\n",
    "    ssh [YOUR USERNAME]@student.ssh.inf.ed.ac.uk\n",
    "    ssh student.login\n",
    "    submit iaml cw2 03_A_ObjectRecognition.ipynb 03_B_MiniChallenge.ipynb\n",
    "    ```\n",
    "    \n",
    "   What actually happens in the background is that your file is placed in a folder available to markers. If you submit a file with the same name into the same location, **it will *overwrite* your previous submission**. You should receive an automatic email confirmation after submission.\n",
    "  \n",
    "\n",
    "\n",
    "### Marking Breakdown\n",
    "\n",
    "The Level 10 and Level 11 points are marked out of different totals, however these are all normalised to 100%. Note that Part A (Object Recognition) is worth 75% of the total Mark for Assignment 3, while Part B (this notebook) is worth 25%. Keep this in mind when allocating time for this assignment.\n",
    "\n",
    "**70-100%** results/answer correct plus extra achievement at understanding or analysis of results. Clear explanations, evidence of creative or deeper thought will contribute to a higher grade.\n",
    "\n",
    "**60-69%** results/answer correct or nearly correct and well explained.\n",
    "\n",
    "**50-59%** results/answer in right direction but significant errors.\n",
    "\n",
    "**40-49%** some evidence that the student has gained some understanding, but not answered the questions\n",
    "properly.\n",
    "\n",
    "**0-39%** serious error or slack work.\n",
    "\n",
    "Note that while this is not a programming assignment, in questions which involve visualisation of results and/or long cold snippets, some marks may be deducted if the code is not adequately readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Use the cell below to include any imports you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwow/miniconda3/envs/py3iaml/lib/python3.7/site-packages/sklearn/utils/__init__.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence\n"
     ]
    }
   ],
   "source": [
    "# Nice Formatting within Jupyter Notebook\n",
    "%matplotlib inline\n",
    "from IPython.display import display # Allows multiple displays from a single code-cell\n",
    "\n",
    "# System functionality\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Here any Additional modules you use. To import utilities we provide, use something like:\n",
    "#   from utils.plotter import plot_hinton\n",
    "\n",
    "# Your Code goes here:\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini challenge\n",
    "\n",
    "In this second part of the assignment we will have a mini object-recognition challenge. Using the same type of data as in Part A, you are asked to find the best classifier for the person/no person classification task. You can apply any preprocessing steps to the data that you think fit and employ any classifier you like (with the provision that you can explain what the classifier is/preprocessing steps are doing). You can also employ any lessons learnt during the course, either from previous Assignments, the Labs or the lecture material to try and squeeze out as much performance as you possibly can. The only restriction is that all steps must be performed in `Python` by using the `numpy`, `pandas` and `sklearn` packages. You can also make use of `matplotlib` and `seaborn` for visualisation.\n",
    "\n",
    "### DataSet Description\n",
    "\n",
    "The datasets we use here are similar in composition but not the same as the ones used in Part A: *it will be useful to revise the description in that notebook*. Specifically, you have access to three new datasets: a training set (`Images_C_Train.csv`), a validation set (`Images_C_Validate.csv`), and a test set (`Images_C_Test.csv`). You must use the former two for training and evaluating your models (as you see fit). As before, the full data-set has 520 attributes (dimensions). Of these you only have access to the 500 features (`dim1` through `dim500`) to test your model on: i.e. the test set does not have any of the class labels.\n",
    "\n",
    "### Model Evaluation\n",
    "\n",
    "Your results will be evaluated in terms of the logarithmic loss metric, specifically the [logloss](http://scikit-learn.org/0.19/modules/model_evaluation.html#log-loss) function from SKLearn. You should familiarise yourself with this. To estimate this metric you will need to provide probability outputs, as opposed to discrete predictions which we have used so far to compute classification accuracies. Most models in `sklearn` implement a `predict_proba()` method which returns the probabilities for each class. For instance, if your test set consists of `N` datapoints and there are `K` class-labels, the method will return an `N` x `K` matrix (with rows summing to 1).\n",
    "\n",
    "### Submission and Scoring\n",
    "\n",
    "This part of Assignment 3 carries 25% of the total marks. Within this, you will be scored on two criteria:\n",
    " 1. 80% of the mark will depend on the thoroughness of the exploration of various approaches. This will be assessed through your code, as well as a brief description (<600 words) justifying the approaches you considered, your exploration pattern and your suggested final approach (and why you chose it).\n",
    " 1. 20% of the mark will depend on the quality of your predictions: this will be evaluated based on the logarithmic loss metric.\n",
    "Note here that just getting exceptional performance is not enough: in fact, you should focus more on analysing your results that just getting the best score!\n",
    "\n",
    "You have to submit the following:\n",
    " 1. **All Code-Cells** which show your **working** with necessary output/plots already generated.\n",
    " 1. In **TEXT** cell `#ANSWER_TEXT#` you are to write your explanation (<600 words) as described above. Keep this brief and to the point. **Make sure** to keep the token `#ANSWER_TEXT#` as the first line of the cell!\n",
    " 1. In **CODE** cell `#ANSWER_PROB#` you are to submit your predictions. To do this:\n",
    "    1. Once you have chosen your favourite model (and pre-processing steps) apply it to the test-set and estimate the posterior proabilities for the data points in the test set.\n",
    "    1. Store these probabilities in a 2D numpy array named `pred_probabilities`, with predictions along the rows i.e. each row should be a complete probability distribution over whether the image contains a person or not. Note that due to the encoding of the `is_person` class, the negative case (i.e. there is no person) comes first.\n",
    "    1. Execute the `#ANSWER_PROB#` code cell, making sure to not change anything. This cell will do some checks to ensure that you are submitting the right shape of array.\n",
    "\n",
    "You may create as many code cells as you need (within reason) for training your models, evaluating the data etc: however, the text cell `#ANSWER_TEXT#` and code-cell `#ANSWER_PROB#` showing your answers must be the last two cells in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "      <th>dim5</th>\n",
       "      <th>dim6</th>\n",
       "      <th>dim7</th>\n",
       "      <th>dim8</th>\n",
       "      <th>dim9</th>\n",
       "      <th>dim10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim491</th>\n",
       "      <th>dim492</th>\n",
       "      <th>dim493</th>\n",
       "      <th>dim494</th>\n",
       "      <th>dim495</th>\n",
       "      <th>dim496</th>\n",
       "      <th>dim497</th>\n",
       "      <th>dim498</th>\n",
       "      <th>dim499</th>\n",
       "      <th>dim500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.002790</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.003627</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>0.000558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008203</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.004297</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.005729</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.003646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015253</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.008152</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.003627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim1      dim2      dim3      dim4      dim5      dim6      dim7  \\\n",
       "0  0.002232  0.000558  0.002790  0.000837  0.001674  0.001953  0.001395   \n",
       "1  0.001563  0.000391  0.007422  0.003516  0.003906  0.005078  0.001953   \n",
       "2  0.000521  0.000000  0.000000  0.001042  0.001563  0.005729  0.000521   \n",
       "3  0.002976  0.002232  0.004464  0.000372  0.000372  0.002232  0.000000   \n",
       "4  0.001359  0.000340  0.001359  0.000340  0.001359  0.002038  0.002378   \n",
       "5  0.000000  0.006324  0.000372  0.000372  0.000372  0.000372  0.000744   \n",
       "6  0.000340  0.000000  0.004416  0.000340  0.000679  0.006114  0.001359   \n",
       "7  0.000837  0.002232  0.000279  0.000279  0.000837  0.000000  0.000279   \n",
       "\n",
       "       dim8      dim9     dim10    ...       dim491    dim492    dim493  \\\n",
       "0  0.002232  0.003627  0.006138    ...     0.001116  0.000558  0.005301   \n",
       "1  0.002344  0.001953  0.001953    ...     0.001953  0.000000  0.008203   \n",
       "2  0.002083  0.003646  0.005208    ...     0.002083  0.000000  0.000521   \n",
       "3  0.003720  0.000000  0.002232    ...     0.001488  0.000000  0.015253   \n",
       "4  0.000000  0.003397  0.003397    ...     0.002038  0.000679  0.000000   \n",
       "5  0.008185  0.000372  0.000372    ...     0.000372  0.005580  0.000744   \n",
       "6  0.002717  0.003057  0.005435    ...     0.000679  0.000000  0.003057   \n",
       "7  0.006696  0.000000  0.000000    ...     0.000558  0.002232  0.004185   \n",
       "\n",
       "     dim494    dim495    dim496    dim497    dim498    dim499    dim500  \n",
       "0  0.001116  0.004185  0.000837  0.006975  0.001953  0.001674  0.000558  \n",
       "1  0.001172  0.007422  0.004297  0.001563  0.000000  0.003125  0.004687  \n",
       "2  0.000521  0.002083  0.000000  0.000000  0.000521  0.003646  0.000000  \n",
       "3  0.000744  0.001488  0.000744  0.000372  0.001860  0.000000  0.001860  \n",
       "4  0.001359  0.001019  0.003736  0.008152  0.003736  0.000679  0.001698  \n",
       "5  0.000000  0.000000  0.000000  0.000000  0.001116  0.000372  0.000372  \n",
       "6  0.001359  0.001698  0.000679  0.006454  0.002378  0.002378  0.001019  \n",
       "7  0.000000  0.000000  0.000837  0.000000  0.000279  0.000279  0.003627  \n",
       "\n",
       "[8 rows x 500 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "5    0\n",
       "6    1\n",
       "7    0\n",
       "Name: is_person, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "validation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "      <th>dim5</th>\n",
       "      <th>dim6</th>\n",
       "      <th>dim7</th>\n",
       "      <th>dim8</th>\n",
       "      <th>dim9</th>\n",
       "      <th>dim10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim491</th>\n",
       "      <th>dim492</th>\n",
       "      <th>dim493</th>\n",
       "      <th>dim494</th>\n",
       "      <th>dim495</th>\n",
       "      <th>dim496</th>\n",
       "      <th>dim497</th>\n",
       "      <th>dim498</th>\n",
       "      <th>dim499</th>\n",
       "      <th>dim500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.004092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.003736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim1      dim2      dim3      dim4      dim5      dim6      dim7  \\\n",
       "0  0.001698  0.000000  0.003057  0.002378  0.001019  0.001698  0.000340   \n",
       "1  0.002038  0.000000  0.004076  0.001019  0.001019  0.001019  0.000679   \n",
       "2  0.001116  0.000000  0.005208  0.001860  0.001116  0.000000  0.001488   \n",
       "3  0.001698  0.000340  0.004076  0.000679  0.002038  0.001019  0.002038   \n",
       "4  0.003736  0.001019  0.000679  0.001019  0.003736  0.002038  0.002038   \n",
       "5  0.002378  0.000000  0.003057  0.002717  0.001698  0.001698  0.001359   \n",
       "6  0.003057  0.000000  0.009511  0.001359  0.001698  0.000340  0.002378   \n",
       "7  0.000744  0.000372  0.001860  0.001860  0.002232  0.002232  0.002604   \n",
       "\n",
       "       dim8      dim9     dim10    ...       dim491    dim492    dim493  \\\n",
       "0  0.001019  0.001359  0.004416    ...     0.004076  0.000000  0.002038   \n",
       "1  0.001019  0.001019  0.002378    ...     0.001019  0.000000  0.003736   \n",
       "2  0.002232  0.001116  0.000372    ...     0.001860  0.000000  0.014137   \n",
       "3  0.001019  0.000340  0.004076    ...     0.001698  0.000340  0.011889   \n",
       "4  0.001359  0.002717  0.001698    ...     0.001698  0.000679  0.000679   \n",
       "5  0.002038  0.005095  0.002717    ...     0.003057  0.000000  0.002378   \n",
       "6  0.005095  0.002038  0.001019    ...     0.001019  0.000340  0.003736   \n",
       "7  0.000372  0.001860  0.004464    ...     0.002604  0.000000  0.005952   \n",
       "\n",
       "     dim494    dim495    dim496    dim497    dim498    dim499    dim500  \n",
       "0  0.000340  0.003397  0.004416  0.000679  0.003736  0.005774  0.007812  \n",
       "1  0.003397  0.005435  0.002038  0.003397  0.001019  0.001359  0.002717  \n",
       "2  0.001116  0.004836  0.001488  0.000372  0.001116  0.001488  0.004092  \n",
       "3  0.001698  0.001698  0.002378  0.002378  0.002038  0.001698  0.001698  \n",
       "4  0.001359  0.001019  0.001019  0.001019  0.002378  0.001359  0.000000  \n",
       "5  0.001698  0.003397  0.000679  0.002038  0.001698  0.001019  0.001019  \n",
       "6  0.000000  0.002717  0.001019  0.001698  0.004755  0.001019  0.003736  \n",
       "7  0.003348  0.001488  0.001488  0.002976  0.001860  0.002232  0.000372  \n",
       "\n",
       "[8 rows x 500 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    1\n",
       "7    1\n",
       "Name: is_person, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "testing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim1</th>\n",
       "      <th>dim2</th>\n",
       "      <th>dim3</th>\n",
       "      <th>dim4</th>\n",
       "      <th>dim5</th>\n",
       "      <th>dim6</th>\n",
       "      <th>dim7</th>\n",
       "      <th>dim8</th>\n",
       "      <th>dim9</th>\n",
       "      <th>dim10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim491</th>\n",
       "      <th>dim492</th>\n",
       "      <th>dim493</th>\n",
       "      <th>dim494</th>\n",
       "      <th>dim495</th>\n",
       "      <th>dim496</th>\n",
       "      <th>dim497</th>\n",
       "      <th>dim498</th>\n",
       "      <th>dim499</th>\n",
       "      <th>dim500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.008832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.020720</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001838</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.003676</td>\n",
       "      <td>0.000919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.007473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.001359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002378</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.004416</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.002378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.006454</td>\n",
       "      <td>0.005095</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.001019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dim1      dim2      dim3      dim4      dim5      dim6      dim7  \\\n",
       "0  0.000000  0.000000  0.000000  0.001019  0.001698  0.000679  0.000679   \n",
       "1  0.000372  0.000000  0.014137  0.000372  0.002232  0.001116  0.000744   \n",
       "2  0.001019  0.000679  0.006793  0.001359  0.000340  0.001359  0.002717   \n",
       "3  0.001379  0.000460  0.003217  0.002757  0.003217  0.004596  0.000919   \n",
       "4  0.001019  0.000340  0.014946  0.003057  0.000340  0.003736  0.000679   \n",
       "5  0.002038  0.000679  0.001019  0.004076  0.002378  0.001019  0.002378   \n",
       "6  0.001698  0.000679  0.002378  0.002038  0.002378  0.001019  0.001359   \n",
       "7  0.002038  0.000340  0.006454  0.005095  0.001019  0.001019  0.001019   \n",
       "\n",
       "       dim8      dim9     dim10    ...       dim491    dim492    dim493  \\\n",
       "0  0.000000  0.005435  0.009171    ...     0.000340  0.000000  0.004755   \n",
       "1  0.008185  0.000372  0.001116    ...     0.000000  0.000000  0.007068   \n",
       "2  0.002038  0.001359  0.000679    ...     0.001698  0.000340  0.020720   \n",
       "3  0.003676  0.001838  0.004596    ...     0.001838  0.000460  0.007353   \n",
       "4  0.002038  0.001019  0.002038    ...     0.002717  0.000000  0.007812   \n",
       "5  0.002038  0.001019  0.001698    ...     0.002717  0.000000  0.000679   \n",
       "6  0.003057  0.002717  0.005435    ...     0.002038  0.002038  0.001698   \n",
       "7  0.001019  0.001019  0.004076    ...     0.003397  0.000000  0.003736   \n",
       "\n",
       "     dim494    dim495    dim496    dim497    dim498    dim499    dim500  \n",
       "0  0.000340  0.000000  0.000340  0.003397  0.000679  0.000679  0.008832  \n",
       "1  0.000372  0.004464  0.003348  0.000744  0.004836  0.000000  0.010045  \n",
       "2  0.002717  0.003397  0.001019  0.001019  0.002378  0.002378  0.003057  \n",
       "3  0.000460  0.002298  0.001379  0.005055  0.006434  0.003676  0.000919  \n",
       "4  0.002378  0.003397  0.003736  0.002717  0.001359  0.002717  0.007473  \n",
       "5  0.000679  0.001698  0.002038  0.003736  0.002717  0.003397  0.001359  \n",
       "6  0.001359  0.004416  0.001019  0.007812  0.001359  0.001019  0.002378  \n",
       "7  0.000340  0.001698  0.000679  0.006114  0.002038  0.003057  0.001019  \n",
       "\n",
       "[8 rows x 500 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    ?\n",
       "1    ?\n",
       "2    ?\n",
       "3    ?\n",
       "4    ?\n",
       "5    ?\n",
       "6    ?\n",
       "7    ?\n",
       "Name: is_person, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load datasets\n",
    "img_c_train = pd.read_csv('datasets/Images_C_Train.csv')\n",
    "X = img_c_train.iloc[:,1:501]\n",
    "y_true = img_c_train['is_person']\n",
    "\n",
    "img_c_val = pd.read_csv('datasets/Images_C_Validate.csv')\n",
    "X_val = img_c_val.iloc[:,1:501]\n",
    "y_val = img_c_val['is_person']\n",
    "\n",
    "img_c_test = pd.read_csv('datasets/Images_C_Test.csv')\n",
    "X_tst = img_c_test.iloc[:,:500]\n",
    "y_tst = img_c_test['is_person']\n",
    "\n",
    "print('training:')\n",
    "display(X.head(8), y_true.head(8))\n",
    "print('-----------------------------------------------')\n",
    "\n",
    "print('validation:')\n",
    "display(X_val.head(8), y_val.head(8))\n",
    "\n",
    "print('-----------------------------------------------')\n",
    "print('testing:')\n",
    "display(X_tst.head(8), y_tst.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier scores\n",
      "-------------------------------\n",
      "Dummy log loss (trn) => 17.02\n",
      "Dummy log loss (val) => 16.38\n",
      "Dummy accuracy (trn) => 50.73%\n",
      "Dummy accuracy (val) => 52.56%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "# establish a baseline for log_loss and accuracy\n",
    "dummy = DummyClassifier(random_state=42).fit(X, y_true)\n",
    "\n",
    "print(\"Dummy classifier scores\")\n",
    "print(\"-------------------------------\")\n",
    "\n",
    "print(\"Dummy log loss (trn) => {:.2f}\".format(log_loss(y_true, dummy.predict_proba(X))))\n",
    "print(\"Dummy log loss (val) => {:.2f}\".format(log_loss(y_val, dummy.predict_proba(X_val))))\n",
    "\n",
    "print(\"Dummy accuracy (trn) => {:.2%}\".format(accuracy_score(y_true, dummy.predict(X))))\n",
    "print(\"Dummy accuracy (val) => {:.2%}\".format(accuracy_score(y_val, dummy.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB log loss (trn) => 18.96\n",
      "NB log loss (val) => 18.18\n",
      " -- NB accuracy (trn) => 45.10%\n",
      " -- NB accuracy (val) => 47.35%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# naive bayes classifier without PCA\n",
    "nb = GaussianNB().fit(X, y_true)\n",
    "\n",
    "p_t = nb.predict_proba(X)\n",
    "p_v = nb.predict_proba(X_val)\n",
    "\n",
    "print(\"NB log loss (trn) => {:.2f}\".format(log_loss(y_true, p_t)))\n",
    "print(\"NB log loss (val) => {:.2f}\".format(log_loss(y_val, p_v)))\n",
    "\n",
    "print(\" -- NB accuracy (trn) => {:.2%}\".format(accuracy_score(y_true, nb.predict(X))))\n",
    "print(\" -- NB accuracy (val) => {:.2%}\".format(accuracy_score(y_val, nb.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=1, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)\n",
      "CPU times: user 23.6 s, sys: 797 ms, total: 24.4 s\n",
      "Wall time: 6.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# analyse PCA with 1 to 50 components, then every 20 steps\n",
    "space = np.concatenate((np.arange(1, 50), np.arange(50, 500, 20))) # np.linspace(1, 500, 100, dtype=int)\n",
    "losses_trn = []\n",
    "losses_val = []\n",
    "\n",
    "# perform exploratory PCA to extract most informative features\n",
    "for n in space:\n",
    "    pca = PCA(n_components=n)\n",
    "    trn_pca = pca.fit_transform(X)\n",
    "    val_pca = pca.transform(X_val)\n",
    "    \n",
    "    _nb = GaussianNB().fit(trn_pca, y_true)\n",
    "    \n",
    "    y_pred_trn = _nb.predict_proba(trn_pca)\n",
    "    y_pred_val = _nb.predict_proba(val_pca)\n",
    "\n",
    "    loss_t = log_loss(y_true, y_pred_trn)\n",
    "    loss_v = log_loss(y_val, y_pred_val)\n",
    "\n",
    "    losses_trn.append(loss_t)\n",
    "    losses_val.append(loss_v)\n",
    "\n",
    "# convert to np arrays\n",
    "losses_trn, losses_val = np.array(losses_trn), np.array(losses_val)\n",
    "# create optimal PCA and fit it\n",
    "pca_opt = PCA(n_components=space[losses_trn.argmin()])\n",
    "X_pca = pca_opt.fit_transform(X)\n",
    "X_val_pca = pca_opt.transform(X_val)\n",
    "\n",
    "print(pca_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lowest logloss (trn) => 0.7594515467031212 (1 components)\n",
      "lowest logloss (val) => 0.692897165153783 (1 components)\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.lineplot(space, losses_trn, label='training data logloss')\n",
    "sns.lineplot(space, losses_val, label='validation data logloss')\n",
    "plt.xlabel(\"number of principal components\")\n",
    "plt.ylabel(\"logloss\")\n",
    "\n",
    "plt.show()\n",
    "print(\"lowest logloss (trn) => {} ({} components)\".format(losses_trn.min(), space[losses_trn.argmin()]))\n",
    "print(\"lowest logloss (val) => {} ({} components)\".format(losses_val.min(), space[losses_val.argmin()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB (PCA) log loss (trn) => 0.76\n",
      "NB (PCA) log loss (val) => 0.69\n",
      "NB (PCA) accuracy (trn) => 55.18%\n",
      "NB (PCA) accuracy (val) => 52.65%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# naive bayes classifier *with* PCA\n",
    "nb_pca = GaussianNB().fit(X_pca, y_true)\n",
    "\n",
    "print(\"NB (PCA) log loss (trn) => {:.2f}\".format(log_loss(y_true, nb_pca.predict_proba(X_pca))))\n",
    "print(\"NB (PCA) log loss (val) => {:.2f}\".format(log_loss(y_val, nb_pca.predict_proba(X_val_pca))))\n",
    "\n",
    "print(\"NB (PCA) accuracy (trn) => {:.2%}\".format(accuracy_score(y_true, nb_pca.predict(X_pca))))\n",
    "print(\"NB (PCA) accuracy (val) => {:.2%}\".format(accuracy_score(y_val, nb_pca.predict(X_val_pca))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "SVC(C=1e-05, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "CPU times: user 719 ms, sys: 578 ms, total: 1.3 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "# use gridsearch\n",
    "param_grid = {'C': np.geomspace(1e-5, 1e2, 10), \n",
    "              'gamma': np.geomspace(1e-5, 1e5, 5)}\n",
    "clf = GridSearchCV(SVC(kernel='rbf', probability=True),\n",
    "                   param_grid, cv=5, n_jobs=-1)\n",
    "clf.fit(X_pca, y_true)\n",
    "print(\"Best estimator found by grid search:\")\n",
    "svc = clf.best_estimator_\n",
    "print(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jwow/miniconda3/envs/py3iaml/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC log loss (trn) => 0.88\n",
      "SVC log loss (val) => 0.92\n",
      " -- SVC accuracy (trn) => 55.18%\n",
      " -- SVC accuracy (val) => 52.65%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "ax = sns.lineplot(x=np.array(clf.cv_results_['param_C'], dtype=float), \n",
    "             y=clf.cv_results_['mean_test_score'])\n",
    "plt.xlabel(\"c parameter\")\n",
    "plt.ylabel(\"mean accuracy\")\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1, 2))\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "print(\"SVC log loss (trn) => {:.2f}\".format(log_loss(y_true, svc.predict_proba(X_pca))))\n",
    "print(\"SVC log loss (val) => {:.2f}\".format(log_loss(y_val, svc.predict_proba(X_val_pca))))\n",
    "print(\" -- SVC accuracy (trn) => {:.2%}\".format(accuracy_score(y_true, svc.predict(X_pca))))\n",
    "print(\" -- SVC accuracy (val) => {:.2%}\".format(accuracy_score(y_val, svc.predict(X_val_pca))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN log loss (trn) => 0.54\n",
      "ANN log loss (val) => 0.60\n",
      " -- ANN accuracy (trn) => 72.17%\n",
      " -- ANN accuracy (val) => 69.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# artificial neural network with 3, 3, 5 intermediate layers\n",
    "ann = MLPClassifier(solver='lbfgs', alpha=5e-2,\n",
    "                    hidden_layer_sizes=(3, 3, 5), random_state=42)\n",
    "ann.fit(X, y_true)\n",
    "print(\"ANN log loss (trn) => {:.2f}\".format(log_loss(y_true, ann.predict_proba(X))))\n",
    "print(\"ANN log loss (val) => {:.2f}\".format(log_loss(y_val, ann.predict_proba(X_val))))\n",
    "print(\" -- ANN accuracy (trn) => {:.2%}\".format(accuracy_score(y_true, ann.predict(X))))\n",
    "print(\" -- ANN accuracy (val) => {:.2%}\".format(accuracy_score(y_val, ann.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probabilities = ann.predict_proba(X_tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ANSWER_TEXT#\n",
    "\n",
    "## Initial\n",
    "- get a feel for the data\n",
    "- start with dummy classifier\n",
    " - log loss: $16.38$ (validation set)\n",
    "\n",
    "## Approaches:\n",
    "1. Principal Component Analysis:\n",
    " - attempt to obtain most variable components as preprocessing helps find variability in data\n",
    " - best combination of components = 1 component (surprising, also given that it becomes worse with more components)\n",
    "1. Naive Bayes classifier:\n",
    " - this first approach was considered due to easy implementation and as a better baseline than the dummy\n",
    "  - log loss (no PCA): $18.18$ - worse than dummy\n",
    "  - log loss ( + PCA): $0.69$ - much better result - PCA definitely did wonders\n",
    "1. SVM classifier:\n",
    " - searching for optimal parameters takes a while\n",
    " - extremely similar results to NB+PCA\n",
    "1. Artificial Neural Network\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88418947, 0.11581053\n",
      "0.93826671, 0.06173329\n",
      "0.37214084, 0.62785916\n",
      "0.55139769, 0.44860231\n",
      "0.81685470, 0.18314530\n",
      "0.20033273, 0.79966727\n",
      "0.31954596, 0.68045404\n",
      "0.19899109, 0.80100891\n",
      "0.97698023, 0.02301977\n",
      "0.73456144, 0.26543856\n",
      "0.28236646, 0.71763354\n",
      "0.79507090, 0.20492910\n",
      "0.50021683, 0.49978317\n",
      "0.76967087, 0.23032913\n",
      "0.11205935, 0.88794065\n",
      "0.59397916, 0.40602084\n",
      "0.09159610, 0.90840390\n",
      "0.53806095, 0.46193905\n",
      "0.87063941, 0.12936059\n",
      "0.51567934, 0.48432066\n",
      "0.95248816, 0.04751184\n",
      "0.64224132, 0.35775868\n",
      "0.85439686, 0.14560314\n",
      "0.30734426, 0.69265574\n",
      "0.73373463, 0.26626537\n",
      "0.16742031, 0.83257969\n",
      "0.31480083, 0.68519917\n",
      "0.91346505, 0.08653495\n",
      "0.39951323, 0.60048677\n",
      "0.43172165, 0.56827835\n",
      "0.76033154, 0.23966846\n",
      "0.43643488, 0.56356512\n",
      "0.88069897, 0.11930103\n",
      "0.59628082, 0.40371918\n",
      "0.76060098, 0.23939902\n",
      "0.48667883, 0.51332117\n",
      "0.23455402, 0.76544598\n",
      "0.85839018, 0.14160982\n",
      "0.90461399, 0.09538601\n",
      "0.76419319, 0.23580681\n",
      "0.66539879, 0.33460121\n",
      "0.51576145, 0.48423855\n",
      "0.48610269, 0.51389731\n",
      "0.97733146, 0.02266854\n",
      "0.03608508, 0.96391492\n",
      "0.43283048, 0.56716952\n",
      "0.43354338, 0.56645662\n",
      "0.93697762, 0.06302238\n",
      "0.22815733, 0.77184267\n",
      "0.97292989, 0.02707011\n",
      "0.89298504, 0.10701496\n",
      "0.48963574, 0.51036426\n",
      "0.30039172, 0.69960828\n",
      "0.19601090, 0.80398910\n",
      "0.36329387, 0.63670613\n",
      "0.24886426, 0.75113574\n",
      "0.56764228, 0.43235772\n",
      "0.48005313, 0.51994687\n",
      "0.67221268, 0.32778732\n",
      "0.14507350, 0.85492650\n",
      "0.95706594, 0.04293406\n",
      "0.88414332, 0.11585668\n",
      "0.94021019, 0.05978981\n",
      "0.16332507, 0.83667493\n",
      "0.65043772, 0.34956228\n",
      "0.31473020, 0.68526980\n",
      "0.79249079, 0.20750921\n",
      "0.95231000, 0.04769000\n",
      "0.17980556, 0.82019444\n",
      "0.87776649, 0.12223351\n",
      "0.74639002, 0.25360998\n",
      "0.86789186, 0.13210814\n",
      "0.03985583, 0.96014417\n",
      "0.63885748, 0.36114252\n",
      "0.59859561, 0.40140439\n",
      "0.07944964, 0.92055036\n",
      "0.76054433, 0.23945567\n",
      "0.76952689, 0.23047311\n",
      "0.21526313, 0.78473687\n",
      "0.27642785, 0.72357215\n",
      "0.32618233, 0.67381767\n",
      "0.70207185, 0.29792815\n",
      "0.46469212, 0.53530788\n",
      "0.31247295, 0.68752705\n",
      "0.65503616, 0.34496384\n",
      "0.07629698, 0.92370302\n",
      "0.61999686, 0.38000314\n",
      "0.54670793, 0.45329207\n",
      "0.56068059, 0.43931941\n",
      "0.40429610, 0.59570390\n",
      "0.77761441, 0.22238559\n",
      "0.36061291, 0.63938709\n",
      "0.26941147, 0.73058853\n",
      "0.36899442, 0.63100558\n",
      "0.20230640, 0.79769360\n",
      "0.61400699, 0.38599301\n",
      "0.84095907, 0.15904093\n",
      "0.71292565, 0.28707435\n",
      "0.42389910, 0.57610090\n",
      "0.17928993, 0.82071007\n",
      "0.70195216, 0.29804784\n",
      "0.48579922, 0.51420078\n",
      "0.94527739, 0.05472261\n",
      "0.61133452, 0.38866548\n",
      "0.17081375, 0.82918625\n",
      "0.72516275, 0.27483725\n",
      "0.22162463, 0.77837537\n",
      "0.36713332, 0.63286668\n",
      "0.05953886, 0.94046114\n",
      "0.87885138, 0.12114862\n",
      "0.66589500, 0.33410500\n",
      "0.20258459, 0.79741541\n",
      "0.43555887, 0.56444113\n",
      "0.55365779, 0.44634221\n",
      "0.22842682, 0.77157318\n",
      "0.96757385, 0.03242615\n",
      "0.26492591, 0.73507409\n",
      "0.51904113, 0.48095887\n",
      "0.52366021, 0.47633979\n",
      "0.21469080, 0.78530920\n",
      "0.90642319, 0.09357681\n",
      "0.60312524, 0.39687476\n",
      "0.99549650, 0.00450350\n",
      "0.37278377, 0.62721623\n",
      "0.68304388, 0.31695612\n",
      "0.15566538, 0.84433462\n",
      "0.73228638, 0.26771362\n",
      "0.45737796, 0.54262204\n",
      "0.41007192, 0.58992808\n",
      "0.31861095, 0.68138905\n",
      "0.89448347, 0.10551653\n",
      "0.28654019, 0.71345981\n",
      "0.74518598, 0.25481402\n",
      "0.54799725, 0.45200275\n",
      "0.79713645, 0.20286355\n",
      "0.86677806, 0.13322194\n",
      "0.85035148, 0.14964852\n",
      "0.77527531, 0.22472469\n",
      "0.66200799, 0.33799201\n",
      "0.64325526, 0.35674474\n",
      "0.30683605, 0.69316395\n",
      "0.15772130, 0.84227870\n",
      "0.82313177, 0.17686823\n",
      "0.60382224, 0.39617776\n",
      "0.95779898, 0.04220102\n",
      "0.35397883, 0.64602117\n",
      "0.33245655, 0.66754345\n",
      "0.38335228, 0.61664772\n",
      "0.73123280, 0.26876720\n",
      "0.69367094, 0.30632906\n",
      "0.29316152, 0.70683848\n",
      "0.35662196, 0.64337804\n",
      "0.95047024, 0.04952976\n",
      "0.48145864, 0.51854136\n",
      "0.59532094, 0.40467906\n",
      "0.39413777, 0.60586223\n",
      "0.59546051, 0.40453949\n",
      "0.21159714, 0.78840286\n",
      "0.42882447, 0.57117553\n",
      "0.36600303, 0.63399697\n",
      "0.60723481, 0.39276519\n",
      "0.20138607, 0.79861393\n",
      "0.80023486, 0.19976514\n",
      "0.41192961, 0.58807039\n",
      "0.77544308, 0.22455692\n",
      "0.83399138, 0.16600862\n",
      "0.91810163, 0.08189837\n",
      "0.39861569, 0.60138431\n",
      "0.89025851, 0.10974149\n",
      "0.24927554, 0.75072446\n",
      "0.89189063, 0.10810937\n",
      "0.89881162, 0.10118838\n",
      "0.62164173, 0.37835827\n",
      "0.46139472, 0.53860528\n",
      "0.25899821, 0.74100179\n",
      "0.65897208, 0.34102792\n",
      "0.15218144, 0.84781856\n",
      "0.41173046, 0.58826954\n",
      "0.38323983, 0.61676017\n",
      "0.94231171, 0.05768829\n",
      "0.35793578, 0.64206422\n",
      "0.90934998, 0.09065002\n",
      "0.72645254, 0.27354746\n",
      "0.08657923, 0.91342077\n",
      "0.29956786, 0.70043214\n",
      "0.59666165, 0.40333835\n",
      "0.49815759, 0.50184241\n",
      "0.58535118, 0.41464882\n",
      "0.68464273, 0.31535727\n",
      "0.80918558, 0.19081442\n",
      "0.18044368, 0.81955632\n",
      "0.27235819, 0.72764181\n",
      "0.10743394, 0.89256606\n",
      "0.65549182, 0.34450818\n",
      "0.84988528, 0.15011472\n",
      "0.75029547, 0.24970453\n",
      "0.96135728, 0.03864272\n",
      "0.36860952, 0.63139048\n",
      "0.42195753, 0.57804247\n",
      "0.19480562, 0.80519438\n",
      "0.19534511, 0.80465489\n",
      "0.91465512, 0.08534488\n",
      "0.25458233, 0.74541767\n",
      "0.18942623, 0.81057377\n",
      "0.50611357, 0.49388643\n",
      "0.46072072, 0.53927928\n",
      "0.57309993, 0.42690007\n",
      "0.86684727, 0.13315273\n",
      "0.49981409, 0.50018591\n",
      "0.92618319, 0.07381681\n",
      "0.13251337, 0.86748663\n",
      "0.39107299, 0.60892701\n",
      "0.71902192, 0.28097808\n",
      "0.94159332, 0.05840668\n",
      "0.31422232, 0.68577768\n",
      "0.59453060, 0.40546940\n",
      "0.36677877, 0.63322123\n",
      "0.38532525, 0.61467475\n",
      "0.98720274, 0.01279726\n",
      "0.98756961, 0.01243039\n",
      "0.94596553, 0.05403447\n",
      "0.75421932, 0.24578068\n",
      "0.95084717, 0.04915283\n",
      "0.81442424, 0.18557576\n",
      "0.62621589, 0.37378411\n",
      "0.11343249, 0.88656751\n",
      "0.24676190, 0.75323810\n",
      "0.20175068, 0.79824932\n",
      "0.81340986, 0.18659014\n",
      "0.66065911, 0.33934089\n",
      "0.62764045, 0.37235955\n",
      "0.96162095, 0.03837905\n",
      "0.89780423, 0.10219577\n",
      "0.59315731, 0.40684269\n",
      "0.38507642, 0.61492358\n",
      "0.60035883, 0.39964117\n",
      "0.51758050, 0.48241950\n",
      "0.97257032, 0.02742968\n",
      "0.93179913, 0.06820087\n",
      "0.47165986, 0.52834014\n",
      "0.47977907, 0.52022093\n",
      "0.86742228, 0.13257772\n",
      "0.28494604, 0.71505396\n",
      "0.33817996, 0.66182004\n",
      "0.49879143, 0.50120857\n",
      "0.91512958, 0.08487042\n",
      "0.50522922, 0.49477078\n",
      "0.43182611, 0.56817389\n",
      "0.65218885, 0.34781115\n",
      "0.38988519, 0.61011481\n",
      "0.75384151, 0.24615849\n",
      "0.36146595, 0.63853405\n",
      "0.36124690, 0.63875310\n",
      "0.55576761, 0.44423239\n",
      "0.76385264, 0.23614736\n",
      "0.10422211, 0.89577789\n",
      "0.37382257, 0.62617743\n",
      "0.72193092, 0.27806908\n",
      "0.19738434, 0.80261566\n",
      "0.85091349, 0.14908651\n",
      "0.80402727, 0.19597273\n",
      "0.77635038, 0.22364962\n",
      "0.99288813, 0.00711187\n",
      "0.54326055, 0.45673945\n",
      "0.32489613, 0.67510387\n",
      "0.72912477, 0.27087523\n",
      "0.79767988, 0.20232012\n",
      "0.67085890, 0.32914110\n",
      "0.79491966, 0.20508034\n",
      "0.62198968, 0.37801032\n",
      "0.98426738, 0.01573262\n",
      "0.84069602, 0.15930398\n",
      "0.56788521, 0.43211479\n",
      "0.36013836, 0.63986164\n",
      "0.70529277, 0.29470723\n",
      "0.27794864, 0.72205136\n",
      "0.34842744, 0.65157256\n",
      "0.32896356, 0.67103644\n",
      "0.61457014, 0.38542986\n",
      "0.86156783, 0.13843217\n",
      "0.62698607, 0.37301393\n",
      "0.57926733, 0.42073267\n",
      "0.88894098, 0.11105902\n",
      "0.72920366, 0.27079634\n",
      "0.97116995, 0.02883005\n",
      "0.85653229, 0.14346771\n",
      "0.51797153, 0.48202847\n",
      "0.95802318, 0.04197682\n",
      "0.44487079, 0.55512921\n",
      "0.77808520, 0.22191480\n",
      "0.99816418, 0.00183582\n",
      "0.75938340, 0.24061660\n",
      "0.20161659, 0.79838341\n",
      "0.59384318, 0.40615682\n",
      "0.93347827, 0.06652173\n",
      "0.35224622, 0.64775378\n",
      "0.99747648, 0.00252352\n",
      "0.66359661, 0.33640339\n",
      "0.58158481, 0.41841519\n",
      "0.60035816, 0.39964184\n",
      "0.85994944, 0.14005056\n",
      "0.93047906, 0.06952094\n",
      "0.91484951, 0.08515049\n",
      "0.90004982, 0.09995018\n",
      "0.15342670, 0.84657330\n",
      "0.28469402, 0.71530598\n",
      "0.91452285, 0.08547715\n",
      "0.46635924, 0.53364076\n",
      "0.50385990, 0.49614010\n",
      "0.61472657, 0.38527343\n",
      "0.61268712, 0.38731288\n",
      "0.68926089, 0.31073911\n",
      "0.85914612, 0.14085388\n",
      "0.73329742, 0.26670258\n",
      "0.81787130, 0.18212870\n",
      "0.39694525, 0.60305475\n",
      "0.24830159, 0.75169841\n",
      "0.11835635, 0.88164365\n",
      "0.18376573, 0.81623427\n",
      "0.69051873, 0.30948127\n",
      "0.80869589, 0.19130411\n",
      "0.53478577, 0.46521423\n",
      "0.21669878, 0.78330122\n",
      "0.62415295, 0.37584705\n",
      "0.36452919, 0.63547081\n",
      "0.71836481, 0.28163519\n",
      "0.70462292, 0.29537708\n",
      "0.71339379, 0.28660621\n",
      "0.79369868, 0.20630132\n",
      "0.92428225, 0.07571775\n",
      "0.86210151, 0.13789849\n",
      "0.87094337, 0.12905663\n",
      "0.74877071, 0.25122929\n",
      "0.76318598, 0.23681402\n",
      "0.37332837, 0.62667163\n",
      "0.06121727, 0.93878273\n",
      "0.74371332, 0.25628668\n",
      "0.38136247, 0.61863753\n",
      "0.41495674, 0.58504326\n",
      "0.78814604, 0.21185396\n",
      "0.77117075, 0.22882925\n",
      "0.79704836, 0.20295164\n",
      "0.40106769, 0.59893231\n",
      "0.23285072, 0.76714928\n",
      "0.39733978, 0.60266022\n",
      "0.32760125, 0.67239875\n",
      "0.53883674, 0.46116326\n",
      "0.87216864, 0.12783136\n",
      "0.34103873, 0.65896127\n",
      "0.33991260, 0.66008740\n",
      "0.42054404, 0.57945596\n",
      "0.36656533, 0.63343467\n",
      "0.45562904, 0.54437096\n",
      "0.48676108, 0.51323892\n",
      "0.16438501, 0.83561499\n",
      "0.81209641, 0.18790359\n",
      "0.36335721, 0.63664279\n",
      "0.53532647, 0.46467353\n",
      "0.26335254, 0.73664746\n",
      "0.11734277, 0.88265723\n",
      "0.25113688, 0.74886312\n",
      "0.97464777, 0.02535223\n",
      "0.75569552, 0.24430448\n",
      "0.60467065, 0.39532935\n",
      "0.38783664, 0.61216336\n",
      "0.94136682, 0.05863318\n",
      "0.36212528, 0.63787472\n",
      "0.25436631, 0.74563369\n",
      "0.14589169, 0.85410831\n",
      "0.92636471, 0.07363529\n",
      "0.32360790, 0.67639210\n",
      "0.48099947, 0.51900053\n",
      "0.80712415, 0.19287585\n",
      "0.58638835, 0.41361165\n",
      "0.38979830, 0.61020170\n",
      "0.55400893, 0.44599107\n",
      "0.17601165, 0.82398835\n",
      "0.15650282, 0.84349718\n",
      "0.85730523, 0.14269477\n",
      "0.56318821, 0.43681179\n",
      "0.87096875, 0.12903125\n",
      "0.49904743, 0.50095257\n",
      "0.74730194, 0.25269806\n",
      "0.84504496, 0.15495504\n",
      "0.80783857, 0.19216143\n",
      "0.36168705, 0.63831295\n",
      "0.89242913, 0.10757087\n",
      "0.55167542, 0.44832458\n",
      "0.68464943, 0.31535057\n",
      "0.90289001, 0.09710999\n",
      "0.27382594, 0.72617406\n",
      "0.99942032, 0.00057968\n",
      "0.30698798, 0.69301202\n",
      "0.33925734, 0.66074266\n",
      "0.27537816, 0.72462184\n",
      "0.76566782, 0.23433218\n",
      "0.59123645, 0.40876355\n",
      "0.34240909, 0.65759091\n",
      "0.57468165, 0.42531835\n",
      "0.86905045, 0.13094955\n",
      "0.83503439, 0.16496561\n",
      "0.44710332, 0.55289668\n",
      "0.30685670, 0.69314330\n",
      "0.90956247, 0.09043753\n",
      "0.39605349, 0.60394651\n",
      "0.91759124, 0.08240876\n",
      "0.45152118, 0.54847882\n",
      "0.70946734, 0.29053266\n",
      "0.86717206, 0.13282794\n",
      "0.23043037, 0.76956963\n",
      "0.10548669, 0.89451331\n",
      "0.15957804, 0.84042196\n",
      "0.47334991, 0.52665009\n",
      "0.89431710, 0.10568290\n",
      "0.25828406, 0.74171594\n",
      "0.80190959, 0.19809041\n",
      "0.31818061, 0.68181939\n",
      "0.67711229, 0.32288771\n",
      "0.21198516, 0.78801484\n",
      "0.62497311, 0.37502689\n",
      "0.61880465, 0.38119535\n",
      "0.91050079, 0.08949921\n",
      "0.59876914, 0.40123086\n",
      "0.38749483, 0.61250517\n",
      "0.91810852, 0.08189148\n",
      "0.57914468, 0.42085532\n",
      "0.95725690, 0.04274310\n",
      "0.96668548, 0.03331452\n",
      "0.55372682, 0.44627318\n",
      "0.93204400, 0.06795600\n",
      "0.82859787, 0.17140213\n",
      "0.89642871, 0.10357129\n",
      "0.23408779, 0.76591221\n",
      "0.16981418, 0.83018582\n",
      "0.96397796, 0.03602204\n",
      "0.70789454, 0.29210546\n",
      "0.37992338, 0.62007662\n",
      "0.29654752, 0.70345248\n",
      "0.37510820, 0.62489180\n",
      "0.82545514, 0.17454486\n",
      "0.86412390, 0.13587610\n",
      "0.57350519, 0.42649481\n",
      "0.58539338, 0.41460662\n",
      "0.93745067, 0.06254933\n",
      "0.38997979, 0.61002021\n",
      "0.29179355, 0.70820645\n",
      "0.62435292, 0.37564708\n",
      "0.46444728, 0.53555272\n",
      "0.83452183, 0.16547817\n",
      "0.76063573, 0.23936427\n",
      "0.74191929, 0.25808071\n",
      "0.58660127, 0.41339873\n",
      "0.55443931, 0.44556069\n",
      "0.95136111, 0.04863889\n",
      "0.35749676, 0.64250324\n",
      "0.74772495, 0.25227505\n",
      "0.33589100, 0.66410900\n",
      "0.67643853, 0.32356147\n",
      "0.73171313, 0.26828687\n",
      "0.12580796, 0.87419204\n",
      "0.95958081, 0.04041919\n",
      "0.34026239, 0.65973761\n",
      "0.32879856, 0.67120144\n",
      "0.19598716, 0.80401284\n",
      "0.79435546, 0.20564454\n",
      "0.19507873, 0.80492127\n",
      "0.67295308, 0.32704692\n",
      "0.49929698, 0.50070302\n",
      "0.75000252, 0.24999748\n",
      "0.70792519, 0.29207481\n",
      "0.67229619, 0.32770381\n",
      "0.87589243, 0.12410757\n",
      "0.61574616, 0.38425384\n",
      "0.25467105, 0.74532895\n",
      "0.56257817, 0.43742183\n",
      "0.16938672, 0.83061328\n",
      "0.64243852, 0.35756148\n",
      "0.42257029, 0.57742971\n",
      "0.54311967, 0.45688033\n",
      "0.93649111, 0.06350889\n",
      "0.31152834, 0.68847166\n",
      "0.44940930, 0.55059070\n",
      "0.34174888, 0.65825112\n",
      "0.82466403, 0.17533597\n",
      "0.26187128, 0.73812872\n",
      "0.79381320, 0.20618680\n",
      "0.73197182, 0.26802818\n",
      "0.83706696, 0.16293304\n",
      "0.56990832, 0.43009168\n",
      "0.71880293, 0.28119707\n",
      "0.72548965, 0.27451035\n",
      "0.49815011, 0.50184989\n",
      "0.25448848, 0.74551152\n",
      "0.94590989, 0.05409011\n",
      "0.21576907, 0.78423093\n",
      "0.73672775, 0.26327225\n",
      "0.72633846, 0.27366154\n",
      "0.97578658, 0.02421342\n",
      "0.46148956, 0.53851044\n",
      "0.18699612, 0.81300388\n",
      "0.85884738, 0.14115262\n",
      "0.68729444, 0.31270556\n",
      "0.64965054, 0.35034946\n",
      "0.09133787, 0.90866213\n",
      "0.04630337, 0.95369663\n",
      "0.79332459, 0.20667541\n",
      "0.66671594, 0.33328406\n",
      "0.71157033, 0.28842967\n",
      "0.49524977, 0.50475023\n",
      "0.48415964, 0.51584036\n",
      "0.32732966, 0.67267034\n",
      "0.52261885, 0.47738115\n",
      "0.91906751, 0.08093249\n",
      "0.74519840, 0.25480160\n",
      "0.37355637, 0.62644363\n",
      "0.66719733, 0.33280267\n",
      "0.63535269, 0.36464731\n",
      "0.98132215, 0.01867785\n",
      "0.42272977, 0.57727023\n",
      "0.18118235, 0.81881765\n",
      "0.92148725, 0.07851275\n",
      "0.28051478, 0.71948522\n",
      "0.67620017, 0.32379983\n",
      "0.24456261, 0.75543739\n",
      "0.86855474, 0.13144526\n",
      "0.30486207, 0.69513793\n",
      "0.35028583, 0.64971417\n",
      "0.61565304, 0.38434696\n",
      "0.09945555, 0.90054445\n",
      "0.42263617, 0.57736383\n",
      "0.85093524, 0.14906476\n",
      "0.26567193, 0.73432807\n",
      "0.25456046, 0.74543954\n",
      "0.35368823, 0.64631177\n",
      "0.19971152, 0.80028848\n",
      "0.52899962, 0.47100038\n",
      "0.72679552, 0.27320448\n",
      "0.51451907, 0.48548093\n",
      "0.15630636, 0.84369364\n",
      "0.36579931, 0.63420069\n",
      "0.80187682, 0.19812318\n",
      "0.52835532, 0.47164468\n",
      "0.92460611, 0.07539389\n",
      "0.54277019, 0.45722981\n",
      "0.85488579, 0.14511421\n",
      "0.30889069, 0.69110931\n",
      "0.22621398, 0.77378602\n",
      "0.56147969, 0.43852031\n",
      "0.28184829, 0.71815171\n",
      "0.55686493, 0.44313507\n",
      "0.86717536, 0.13282464\n",
      "0.77932160, 0.22067840\n",
      "0.96429343, 0.03570657\n",
      "0.37991292, 0.62008708\n",
      "0.70734235, 0.29265765\n",
      "0.76654793, 0.23345207\n",
      "0.58901858, 0.41098142\n",
      "0.14927361, 0.85072639\n",
      "0.59771162, 0.40228838\n",
      "0.10558355, 0.89441645\n",
      "0.93105906, 0.06894094\n",
      "0.85264751, 0.14735249\n",
      "0.71145423, 0.28854577\n",
      "0.36880671, 0.63119329\n",
      "0.30945743, 0.69054257\n",
      "0.88922579, 0.11077421\n",
      "0.39015214, 0.60984786\n",
      "0.22088130, 0.77911870\n",
      "0.05911449, 0.94088551\n",
      "0.59295954, 0.40704046\n",
      "0.18126782, 0.81873218\n",
      "0.18565084, 0.81434916\n",
      "0.57444929, 0.42555071\n",
      "0.76213101, 0.23786899\n",
      "0.20815313, 0.79184687\n",
      "0.69848139, 0.30151861\n",
      "0.63875772, 0.36124228\n",
      "0.48722153, 0.51277847\n",
      "0.81068213, 0.18931787\n",
      "0.16913670, 0.83086330\n",
      "0.31250546, 0.68749454\n",
      "0.23439998, 0.76560002\n",
      "0.84234557, 0.15765443\n",
      "0.37524219, 0.62475781\n",
      "0.90465778, 0.09534222\n",
      "0.65842236, 0.34157764\n",
      "0.31006273, 0.68993727\n",
      "0.59551105, 0.40448895\n",
      "0.65672664, 0.34327336\n",
      "0.91949309, 0.08050691\n",
      "0.95644016, 0.04355984\n",
      "0.36561569, 0.63438431\n",
      "0.58123316, 0.41876684\n",
      "0.89190552, 0.10809448\n",
      "0.62132225, 0.37867775\n",
      "0.33461993, 0.66538007\n",
      "0.69568625, 0.30431375\n",
      "0.83779664, 0.16220336\n",
      "0.61326415, 0.38673585\n",
      "0.72523348, 0.27476652\n",
      "0.92127907, 0.07872093\n",
      "0.78505226, 0.21494774\n",
      "0.32728598, 0.67271402\n",
      "0.30055039, 0.69944961\n",
      "0.39269878, 0.60730122\n",
      "0.35643221, 0.64356779\n",
      "0.63030994, 0.36969006\n",
      "0.71718340, 0.28281660\n",
      "0.38858961, 0.61141039\n",
      "0.48036030, 0.51963970\n",
      "0.31804180, 0.68195820\n",
      "0.75905943, 0.24094057\n",
      "0.82796673, 0.17203327\n",
      "0.80115556, 0.19884444\n",
      "0.29634822, 0.70365178\n",
      "0.51733515, 0.48266485\n",
      "0.26932709, 0.73067291\n",
      "0.86062857, 0.13937143\n",
      "0.89626901, 0.10373099\n",
      "0.57156789, 0.42843211\n",
      "0.86487186, 0.13512814\n",
      "0.91422882, 0.08577118\n",
      "0.44493984, 0.55506016\n",
      "0.51739745, 0.48260255\n",
      "0.24918126, 0.75081874\n",
      "0.61120510, 0.38879490\n",
      "0.22058715, 0.77941285\n",
      "0.48469677, 0.51530323\n",
      "0.59178129, 0.40821871\n",
      "0.96234670, 0.03765330\n",
      "0.55547774, 0.44452226\n",
      "0.71027042, 0.28972958\n",
      "0.54517668, 0.45482332\n",
      "0.63185801, 0.36814199\n",
      "0.50295525, 0.49704475\n",
      "0.16618610, 0.83381390\n",
      "0.65397265, 0.34602735\n",
      "0.33361367, 0.66638633\n",
      "0.72184893, 0.27815107\n",
      "0.22067656, 0.77932344\n",
      "0.75429828, 0.24570172\n",
      "0.26687018, 0.73312982\n",
      "0.16816693, 0.83183307\n",
      "0.96553493, 0.03446507\n",
      "0.95526445, 0.04473555\n",
      "0.32362825, 0.67637175\n",
      "0.81199455, 0.18800545\n",
      "0.84352941, 0.15647059\n",
      "0.82897021, 0.17102979\n",
      "0.73383805, 0.26616195\n",
      "0.94614711, 0.05385289\n",
      "0.16740688, 0.83259312\n",
      "0.59912327, 0.40087673\n",
      "0.80317211, 0.19682789\n",
      "0.07594222, 0.92405778\n",
      "0.89413852, 0.10586148\n",
      "0.09082854, 0.90917146\n",
      "0.18447343, 0.81552657\n",
      "0.49238845, 0.50761155\n",
      "0.34526223, 0.65473777\n",
      "0.30964278, 0.69035722\n",
      "0.60359169, 0.39640831\n",
      "0.84936041, 0.15063959\n",
      "0.92222689, 0.07777311\n",
      "0.56689824, 0.43310176\n",
      "0.96123764, 0.03876236\n",
      "0.25482051, 0.74517949\n",
      "0.41981071, 0.58018929\n",
      "0.85468993, 0.14531007\n",
      "0.57347586, 0.42652414\n",
      "0.89972967, 0.10027033\n",
      "0.58704671, 0.41295329\n",
      "0.25246567, 0.74753433\n",
      "0.84506194, 0.15493806\n",
      "0.33310760, 0.66689240\n",
      "0.33129594, 0.66870406\n",
      "0.64969930, 0.35030070\n",
      "0.76563197, 0.23436803\n",
      "0.49999515, 0.50000485\n",
      "0.90916823, 0.09083177\n",
      "0.80580529, 0.19419471\n",
      "0.45266404, 0.54733596\n",
      "0.17521668, 0.82478332\n",
      "0.64468708, 0.35531292\n",
      "0.87563262, 0.12436738\n",
      "0.45650800, 0.54349200\n",
      "0.34261057, 0.65738943\n",
      "0.61814799, 0.38185201\n",
      "0.31370831, 0.68629169\n",
      "0.49859729, 0.50140271\n",
      "0.81704631, 0.18295369\n",
      "0.58775254, 0.41224746\n",
      "0.84860708, 0.15139292\n",
      "0.30034924, 0.69965076\n",
      "0.63385481, 0.36614519\n",
      "0.70933742, 0.29066258\n",
      "0.88482164, 0.11517836\n",
      "0.37889797, 0.62110203\n",
      "0.91814821, 0.08185179\n",
      "0.35113810, 0.64886190\n",
      "0.85635587, 0.14364413\n",
      "0.66521130, 0.33478870\n",
      "0.08873868, 0.91126132\n",
      "0.63678292, 0.36321708\n",
      "0.47594470, 0.52405530\n",
      "0.90246106, 0.09753894\n",
      "0.20231978, 0.79768022\n",
      "0.07400431, 0.92599569\n",
      "0.34933730, 0.65066270\n",
      "0.96479513, 0.03520487\n",
      "0.66411518, 0.33588482\n",
      "0.58520636, 0.41479364\n",
      "0.91131697, 0.08868303\n",
      "0.75092827, 0.24907173\n",
      "0.82830530, 0.17169470\n",
      "0.58416053, 0.41583947\n",
      "0.12016780, 0.87983220\n",
      "0.41864991, 0.58135009\n",
      "0.24948210, 0.75051790\n",
      "0.34849271, 0.65150729\n",
      "0.42050242, 0.57949758\n",
      "0.22842316, 0.77157684\n",
      "0.92075793, 0.07924207\n",
      "0.29936535, 0.70063465\n",
      "0.56471998, 0.43528002\n",
      "0.79996466, 0.20003534\n",
      "0.38249337, 0.61750663\n",
      "0.72588621, 0.27411379\n",
      "0.54576008, 0.45423992\n",
      "0.24785098, 0.75214902\n",
      "0.74535511, 0.25464489\n",
      "0.59699737, 0.40300263\n",
      "0.31059184, 0.68940816\n",
      "0.21426257, 0.78573743\n",
      "0.81051664, 0.18948336\n",
      "0.49462882, 0.50537118\n",
      "0.57690384, 0.42309616\n",
      "0.90846283, 0.09153717\n",
      "0.26438536, 0.73561464\n",
      "0.94992452, 0.05007548\n",
      "0.99570830, 0.00429170\n",
      "0.81454828, 0.18545172\n",
      "0.97646676, 0.02353324\n",
      "0.28286541, 0.71713459\n",
      "0.95707845, 0.04292155\n",
      "0.62158409, 0.37841591\n",
      "0.42769604, 0.57230396\n",
      "0.14657574, 0.85342426\n",
      "0.19052158, 0.80947842\n",
      "0.72901200, 0.27098800\n",
      "0.91649489, 0.08350511\n",
      "0.51827823, 0.48172177\n",
      "0.21879963, 0.78120037\n",
      "0.69908671, 0.30091329\n",
      "0.93419477, 0.06580523\n",
      "0.37668839, 0.62331161\n",
      "0.89873220, 0.10126780\n",
      "0.33652037, 0.66347963\n",
      "0.31164505, 0.68835495\n",
      "0.68952726, 0.31047274\n",
      "0.26686227, 0.73313773\n",
      "0.21831985, 0.78168015\n",
      "0.21270100, 0.78729900\n",
      "0.79543230, 0.20456770\n",
      "0.48822130, 0.51177870\n",
      "0.33087785, 0.66912215\n",
      "0.18678046, 0.81321954\n",
      "0.69672100, 0.30327900\n",
      "0.60008596, 0.39991404\n",
      "0.06029800, 0.93970200\n",
      "0.89301140, 0.10698860\n",
      "0.29136796, 0.70863204\n",
      "0.68673744, 0.31326256\n",
      "0.09590893, 0.90409107\n",
      "0.69110411, 0.30889589\n",
      "0.62223973, 0.37776027\n",
      "0.58305416, 0.41694584\n",
      "0.70279927, 0.29720073\n",
      "0.39217775, 0.60782225\n",
      "0.45009315, 0.54990685\n",
      "0.68685020, 0.31314980\n",
      "0.75418862, 0.24581138\n",
      "0.83624269, 0.16375731\n",
      "0.87420627, 0.12579373\n",
      "0.76192315, 0.23807685\n",
      "0.64923592, 0.35076408\n",
      "0.35048881, 0.64951119\n",
      "0.77933394, 0.22066606\n",
      "0.64081465, 0.35918535\n",
      "0.63367555, 0.36632445\n",
      "0.09907154, 0.90092846\n",
      "0.16477523, 0.83522477\n",
      "0.09083570, 0.90916430\n",
      "0.74235282, 0.25764718\n",
      "0.78580883, 0.21419117\n",
      "0.76710348, 0.23289652\n",
      "0.34767379, 0.65232621\n",
      "0.36001340, 0.63998660\n",
      "0.56544985, 0.43455015\n",
      "0.62364543, 0.37635457\n",
      "0.17047441, 0.82952559\n",
      "0.24959918, 0.75040082\n",
      "0.16354610, 0.83645390\n",
      "0.38123118, 0.61876882\n",
      "0.92851178, 0.07148822\n",
      "0.56571948, 0.43428052\n",
      "0.60778528, 0.39221472\n",
      "0.09914349, 0.90085651\n",
      "0.92921519, 0.07078481\n",
      "0.92434909, 0.07565091\n",
      "0.77802803, 0.22197197\n",
      "0.48328359, 0.51671641\n",
      "0.73623576, 0.26376424\n",
      "0.19395873, 0.80604127\n",
      "0.67224063, 0.32775937\n",
      "0.47597778, 0.52402222\n",
      "0.24943352, 0.75056648\n",
      "0.70647980, 0.29352020\n",
      "0.54985120, 0.45014880\n",
      "0.57328410, 0.42671590\n",
      "0.41584483, 0.58415517\n",
      "0.37284901, 0.62715099\n",
      "0.73607023, 0.26392977\n",
      "0.82622413, 0.17377587\n",
      "0.65776846, 0.34223154\n",
      "0.99672780, 0.00327220\n",
      "0.18786185, 0.81213815\n",
      "0.37159598, 0.62840402\n",
      "0.82467354, 0.17532646\n",
      "0.42948340, 0.57051660\n",
      "0.40186533, 0.59813467\n",
      "0.99352639, 0.00647361\n",
      "0.57214797, 0.42785203\n",
      "0.39992887, 0.60007113\n",
      "0.53086036, 0.46913964\n",
      "0.39042556, 0.60957444\n",
      "0.10417003, 0.89582997\n",
      "0.92998014, 0.07001986\n",
      "0.34854186, 0.65145814\n",
      "0.57285435, 0.42714565\n",
      "0.21468781, 0.78531219\n",
      "0.84602028, 0.15397972\n",
      "0.76510641, 0.23489359\n",
      "0.51495752, 0.48504248\n",
      "0.92741207, 0.07258793\n",
      "0.79473496, 0.20526504\n",
      "0.17522921, 0.82477079\n",
      "0.19437493, 0.80562507\n",
      "0.69235751, 0.30764249\n",
      "0.90756603, 0.09243397\n",
      "0.31069649, 0.68930351\n",
      "0.19058772, 0.80941228\n",
      "0.56317733, 0.43682267\n",
      "0.29289271, 0.70710729\n",
      "0.77099862, 0.22900138\n",
      "0.31487713, 0.68512287\n",
      "0.57913916, 0.42086084\n",
      "0.08660992, 0.91339008\n",
      "0.57275219, 0.42724781\n",
      "0.15416555, 0.84583445\n",
      "0.89604510, 0.10395490\n",
      "0.35150064, 0.64849936\n",
      "0.98377579, 0.01622421\n",
      "0.45368854, 0.54631146\n",
      "0.52544469, 0.47455531\n",
      "0.26410443, 0.73589557\n",
      "0.17207281, 0.82792719\n",
      "0.79882053, 0.20117947\n",
      "0.65767989, 0.34232011\n",
      "0.70488336, 0.29511664\n",
      "0.28106830, 0.71893170\n",
      "0.29636600, 0.70363400\n",
      "0.80042979, 0.19957021\n",
      "0.69575276, 0.30424724\n",
      "0.61151776, 0.38848224\n",
      "0.86596325, 0.13403675\n",
      "0.79986780, 0.20013220\n",
      "0.80653649, 0.19346351\n",
      "0.70674022, 0.29325978\n",
      "0.62689737, 0.37310263\n",
      "0.31426848, 0.68573152\n",
      "0.28739817, 0.71260183\n",
      "0.20051798, 0.79948202\n",
      "0.81121800, 0.18878200\n",
      "0.38596257, 0.61403743\n",
      "0.93944550, 0.06055450\n",
      "0.76002667, 0.23997333\n",
      "0.36515482, 0.63484518\n",
      "0.82179241, 0.17820759\n",
      "0.38070157, 0.61929843\n",
      "0.11239143, 0.88760857\n",
      "0.43415735, 0.56584265\n",
      "0.32208115, 0.67791885\n",
      "0.31668016, 0.68331984\n",
      "0.95951894, 0.04048106\n",
      "0.61318208, 0.38681792\n",
      "0.89274565, 0.10725435\n",
      "0.32039395, 0.67960605\n",
      "0.39152748, 0.60847252\n",
      "0.11827094, 0.88172906\n",
      "0.24423621, 0.75576379\n",
      "0.66786519, 0.33213481\n",
      "0.75198787, 0.24801213\n",
      "0.40717722, 0.59282278\n",
      "0.26730506, 0.73269494\n",
      "0.96880451, 0.03119549\n",
      "0.25360210, 0.74639790\n",
      "0.32946396, 0.67053604\n",
      "0.66128304, 0.33871696\n",
      "0.27600658, 0.72399342\n",
      "0.71913813, 0.28086187\n",
      "0.76792280, 0.23207720\n",
      "0.55902281, 0.44097719\n",
      "0.19095562, 0.80904438\n",
      "0.48308380, 0.51691620\n",
      "0.30300758, 0.69699242\n",
      "0.19657013, 0.80342987\n",
      "0.90232746, 0.09767254\n",
      "0.20989508, 0.79010492\n",
      "0.58686328, 0.41313672\n",
      "0.29647666, 0.70352334\n",
      "0.80803321, 0.19196679\n",
      "0.29858715, 0.70141285\n",
      "0.41038889, 0.58961111\n",
      "0.32455500, 0.67544500\n",
      "0.75221750, 0.24778250\n",
      "0.32564411, 0.67435589\n",
      "0.93910826, 0.06089174\n",
      "0.81841807, 0.18158193\n",
      "0.38643448, 0.61356552\n",
      "0.47850052, 0.52149948\n",
      "0.53997750, 0.46002250\n",
      "0.71168629, 0.28831371\n",
      "0.37551097, 0.62448903\n",
      "0.20111644, 0.79888356\n",
      "0.25672798, 0.74327202\n",
      "0.57226973, 0.42773027\n",
      "0.82658425, 0.17341575\n",
      "0.22110123, 0.77889877\n",
      "0.51021334, 0.48978666\n",
      "0.37971633, 0.62028367\n",
      "0.22996684, 0.77003316\n",
      "0.49262502, 0.50737498\n",
      "0.10310501, 0.89689499\n",
      "0.90401552, 0.09598448\n",
      "0.44166925, 0.55833075\n",
      "0.83175851, 0.16824149\n",
      "0.72581690, 0.27418310\n",
      "0.74821003, 0.25178997\n",
      "0.52023510, 0.47976490\n",
      "0.35532323, 0.64467677\n",
      "0.82799749, 0.17200251\n",
      "0.10586400, 0.89413600\n",
      "0.35776673, 0.64223327\n",
      "0.45863599, 0.54136401\n",
      "0.53351501, 0.46648499\n",
      "0.55736164, 0.44263836\n",
      "0.10031034, 0.89968966\n",
      "0.99989520, 0.00010480\n",
      "0.43400668, 0.56599332\n",
      "0.63464480, 0.36535520\n",
      "0.94051980, 0.05948020\n",
      "0.61121171, 0.38878829\n",
      "0.10412794, 0.89587206\n",
      "0.45353093, 0.54646907\n",
      "0.59707619, 0.40292381\n",
      "0.95661085, 0.04338915\n",
      "0.61092039, 0.38907961\n",
      "0.93645985, 0.06354015\n",
      "0.45963705, 0.54036295\n",
      "0.96508211, 0.03491789\n",
      "0.96725053, 0.03274947\n",
      "0.29047171, 0.70952829\n",
      "0.88887171, 0.11112829\n",
      "0.87816351, 0.12183649\n",
      "0.84581605, 0.15418395\n",
      "0.33435345, 0.66564655\n",
      "0.20699640, 0.79300360\n",
      "0.80710500, 0.19289500\n",
      "0.13195066, 0.86804934\n",
      "0.40071630, 0.59928370\n",
      "0.60076978, 0.39923022\n",
      "0.38941523, 0.61058477\n",
      "0.87721282, 0.12278718\n",
      "0.50702510, 0.49297490\n",
      "0.51069180, 0.48930820\n",
      "0.89248774, 0.10751226\n",
      "0.53464580, 0.46535420\n",
      "0.11090319, 0.88909681\n",
      "0.66534504, 0.33465496\n",
      "0.30096771, 0.69903229\n",
      "0.58365271, 0.41634729\n",
      "0.89188647, 0.10811353\n",
      "0.99848329, 0.00151671\n",
      "0.48639773, 0.51360227\n",
      "0.13494763, 0.86505237\n",
      "0.57235380, 0.42764620\n",
      "0.26165780, 0.73834220\n",
      "0.91238880, 0.08761120\n",
      "0.71069597, 0.28930403\n",
      "0.82060824, 0.17939176\n",
      "0.16772005, 0.83227995\n",
      "0.73709542, 0.26290458\n",
      "0.30441784, 0.69558216\n",
      "0.91944960, 0.08055040\n",
      "0.33693578, 0.66306422\n",
      "0.91704338, 0.08295662\n",
      "0.24634152, 0.75365848\n",
      "0.93475763, 0.06524237\n",
      "0.15492929, 0.84507071\n",
      "0.98172739, 0.01827261\n",
      "0.77394008, 0.22605992\n",
      "0.75142692, 0.24857308\n",
      "0.24565521, 0.75434479\n",
      "0.70817225, 0.29182775\n",
      "0.04064718, 0.95935282\n",
      "0.76848139, 0.23151861\n",
      "0.27282996, 0.72717004\n",
      "0.81070635, 0.18929365\n",
      "0.38657384, 0.61342616\n",
      "0.84164840, 0.15835160\n",
      "0.19806338, 0.80193662\n",
      "0.89315657, 0.10684343\n",
      "0.79985170, 0.20014830\n",
      "0.32329100, 0.67670900\n",
      "0.87507942, 0.12492058\n",
      "0.34573586, 0.65426414\n",
      "0.78108109, 0.21891891\n",
      "0.86304944, 0.13695056\n",
      "0.90141849, 0.09858151\n",
      "0.55123274, 0.44876726\n",
      "0.74678742, 0.25321258\n",
      "0.18410530, 0.81589470\n",
      "0.98893770, 0.01106230\n",
      "0.85589847, 0.14410153\n",
      "0.95446533, 0.04553467\n",
      "0.70452951, 0.29547049\n",
      "0.25412316, 0.74587684\n",
      "0.64078633, 0.35921367\n",
      "0.52464797, 0.47535203\n",
      "0.45780358, 0.54219642\n",
      "0.84060615, 0.15939385\n",
      "0.83431465, 0.16568535\n",
      "0.41127563, 0.58872437\n",
      "0.90888497, 0.09111503\n",
      "0.37357060, 0.62642940\n",
      "0.44151019, 0.55848981\n",
      "0.60909392, 0.39090608\n",
      "0.32409491, 0.67590509\n",
      "0.25198337, 0.74801663\n",
      "0.64752962, 0.35247038\n",
      "0.93124537, 0.06875463\n",
      "0.41413072, 0.58586928\n",
      "0.26582632, 0.73417368\n",
      "0.30533690, 0.69466310\n",
      "0.30148204, 0.69851796\n",
      "0.38626760, 0.61373240\n",
      "0.25642740, 0.74357260\n",
      "0.52020483, 0.47979517\n",
      "0.61533547, 0.38466453\n",
      "0.62283782, 0.37716218\n",
      "0.53703490, 0.46296510\n",
      "0.83647232, 0.16352768\n",
      "0.60568822, 0.39431178\n",
      "0.89065819, 0.10934181\n",
      "0.40628747, 0.59371253\n",
      "0.31955107, 0.68044893\n",
      "0.62145996, 0.37854004\n",
      "0.88145325, 0.11854675\n",
      "0.37153107, 0.62846893\n",
      "0.90500110, 0.09499890\n",
      "0.44470475, 0.55529525\n",
      "0.24105381, 0.75894619\n",
      "0.36210320, 0.63789680\n",
      "0.18669068, 0.81330932\n",
      "0.35390472, 0.64609528\n",
      "0.43682944, 0.56317056\n",
      "0.48267476, 0.51732524\n",
      "0.89946519, 0.10053481\n",
      "0.37456971, 0.62543029\n",
      "0.25387201, 0.74612799\n",
      "0.75410073, 0.24589927\n",
      "0.53026526, 0.46973474\n",
      "0.84227298, 0.15772702\n",
      "0.63886359, 0.36113641\n",
      "0.94538259, 0.05461741\n",
      "0.57672631, 0.42327369\n",
      "0.35821240, 0.64178760\n",
      "0.99414875, 0.00585125\n",
      "0.51824857, 0.48175143\n",
      "0.71444669, 0.28555331\n",
      "0.42674843, 0.57325157\n",
      "0.03126103, 0.96873897\n",
      "0.81140193, 0.18859807\n",
      "0.27376784, 0.72623216\n",
      "0.32207629, 0.67792371\n",
      "0.79779854, 0.20220146\n",
      "0.32419274, 0.67580726\n",
      "0.77222509, 0.22777491\n",
      "0.57418399, 0.42581601\n",
      "0.37210129, 0.62789871\n",
      "0.24618805, 0.75381195\n",
      "0.27286797, 0.72713203\n",
      "0.35518620, 0.64481380\n",
      "0.73889942, 0.26110058\n",
      "0.21430891, 0.78569109\n",
      "0.93939198, 0.06060802\n",
      "0.82175272, 0.17824728\n",
      "0.73705077, 0.26294923\n",
      "0.92064511, 0.07935489\n",
      "0.84423361, 0.15576639\n",
      "0.37587993, 0.62412007\n",
      "0.56908962, 0.43091038\n",
      "0.13112965, 0.86887035\n"
     ]
    }
   ],
   "source": [
    "#ANSWER_PROB#\n",
    "# Run this cell when you are ready to submit your test-set probabilities. This cell will generate some\n",
    "# warning messages if something is not right: make sure to address them!\n",
    "if pred_probabilities.shape != (1114, 2):\n",
    "    print('Array is of incorrect shape. Rectify this before submitting.')\n",
    "elif (pred_probabilities.sum(axis=1) != 1.0).all():\n",
    "    print('Submitted values are not correct probabilities. Rectify this before submitting.')\n",
    "else:\n",
    "    for _prob in pred_probabilities:\n",
    "        print('{:.8f}, {:.8f}'.format(_prob[0], _prob[1]))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
